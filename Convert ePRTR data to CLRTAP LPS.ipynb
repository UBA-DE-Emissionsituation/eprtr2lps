{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert ePRTR data to CLRTAP LPS submission\n",
    "Germany's thru.de website offers the German ePRTR dataset as a SQLITE database. In this script, I convert the data given to the LRTAP convention's Excel template format. On the way, some information is augmented from other sources, in particular stack heights and GNFR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "import csv\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and transform database content "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start and connect to the database as downloaded from https://www.thru.de/thrude/downloads/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database contains a couple of tables, but we are mainly interested in `facilities`, `activities` and `releases`. The `facilities` table already has the list of point sources we need and offers some properties right away. We can simply grap the names and coordinates, for example. As we only need the most current data, we will also filter on the `year` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to match the point source's category (`prtr_id`) and the emissions from the `activities` and `releases` tables respectivly. Note that `releases` has more data than just emissions, so we need to filter for the correct `compartment`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query to achieve these two steps looks something like this:\n",
    "```\n",
    "SELECT name, prtr_key, wgs84_x, wgs84_y, substance_name, annual_load, [...]\n",
    "FROM facilities\n",
    "INNER JOIN activities ON facilities.id = activities.facility_id\n",
    "INNER JOIN releases ON facilities.id = releases.facility_id\n",
    "WHERE facilities.year = <year> and releases.compartment = 'Air')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query will deliver a list of point sources and their releases, but there is still one row per pollutant. To get closer to our CLRTAP template, we need to transpose these emissions to columns and groups them by point source.\n",
    "\n",
    "```\n",
    "SELECT\n",
    "\tname,\n",
    "\tprtr_key AS 'GNFR (TODO)',\n",
    "\tadministrative_number AS 'E-PRTR ID',\n",
    "\t'' AS 'Height class (TODO)',\n",
    "\twgs84_x, wgs84_y,\n",
    "\tSUM(annual_load / 1000000) FILTER (WHERE substance_name = 'Nitrogen oxides (NOx/NO2)') AS 'NOx (as NO2) [kt]',\n",
    "\tSUM(annual_load / 1000000) FILTER (WHERE substance_name = 'Sulphur oxides (SOx/SO2)') AS 'SOx (as SO2) [kt]',\n",
    "    [...]\n",
    "FROM ( <inner query> )\n",
    "GROUP BY id\n",
    "ORDER BY name\n",
    "```\n",
    "\n",
    "Before we go ahead and test all this out, let's list a few underlying assumptions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Database content pre-conditions\n",
    "There are a few things we take for granted when working with the data source, including:\n",
    "* All release annual load values are given in [kg]\n",
    "* facilities.year == release.year for all joins on facilities.id\n",
    "* All substance names are correctly register, no misspellings etc.\n",
    "\n",
    "Okay, with this out of the way, let's go and try this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = sql.connect('../source/prtr_en.db')\n",
    "\n",
    "sql_string = open('../sql/all lps one year.sql', mode='r', encoding='utf-8-sig').read()\n",
    "data = pd.read_sql_query(sql_string, connection)\n",
    "\n",
    "connection.close()\n",
    "\n",
    "data.info(verbose=True)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values('NOx (as NO2) [kt]', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.sort_values('SOx (as SO2) [kt]', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.sort_values('NH3 [kt]', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add GNFR and stack height information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to map the PRTR activities to their GNFR equivalents.\n",
    "We do the same for the stack heights using the UBA Report FKZ:3717511010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnfr_mapping = {}\n",
    "with open('../source/GNFR mapping neo filled.csv', newline='') as mapping_file: \n",
    "    for line in csv.reader(mapping_file, delimiter=';'): \n",
    "        gnfr_mapping[line[0]] = line[2]\n",
    "stack_mapping={}\n",
    "with open('../source/GNFR mapping neo filled.csv', newline='') as mapping_file: \n",
    "    for line in csv.reader(mapping_file, delimiter=';'): \n",
    "        stack_mapping[line[0]] = line[3]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.replace({'GNFR (TODO)': gnfr_mapping}, inplace=True)\n",
    "data.replace({'Height class (TODO)': stack_mapping}, inplace=True)\n",
    "data.rename(columns={'GNFR (TODO': 'GNFR'}, inplace=True)\n",
    "data.rename(columns={'Height class (TODO)' : 'Height class'}, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write result out as csv (to be copied to the Excel template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['PRTR activity (DELETE!)', 'NACE (DELETE!)'], inplace=True)\n",
    "data.to_csv('../target/output.csv', sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
