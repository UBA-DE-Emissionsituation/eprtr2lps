{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# import DataFrame from pandas in order to convert the sql query in a DataFrame\n",
    "from pandas import DataFrame\n",
    "\n",
    "# The ipython-sql library is loaded using the %load_ext iPython extension\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Make sure ePRTR database is in good shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Check db_preconditions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read data from ePRTR database into pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2018'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql sqlite:///data/prtr_en.db sql_query_result << \n",
    "\n",
    "SELECT \n",
    "    facilities.name AS LPS, \n",
    "    activities.prtr_key AS 'PRTR activity',\n",
    "    nace_code || ': ' || nace_text AS 'NACE',\n",
    "    activities.prtr_key AS 'GNFR', \n",
    "    facilities.administrative_number AS 'E-PRTR/PRTR Facility ID', \n",
    "    activities.prtr_key AS 'Height class',\n",
    "    facilities.wgs84_x AS 'Longitude (deg)', \n",
    "    facilities.wgs84_y AS 'Latitude (deg)',\n",
    "\n",
    "    SUM(releases.annual_load/1000000) FILTER (WHERE substance_name = 'Nitrogen oxides (NOx/NO2)') AS \"NOx (as NO2) (kt)\",\n",
    "    SUM(releases.annual_load/1000000) FILTER (WHERE substance_name = 'Non-methane volatile organic compounds (NMVOC)') \n",
    "    AS \"NMVOC (kt)\",\n",
    "    SUM(releases.annual_load/1000000) FILTER (WHERE substance_name = 'Sulphur oxides (SOx/SO2)') AS \"SOx (as SO2) (kt)\",\n",
    "    SUM(releases.annual_load/1000000) FILTER (WHERE substance_name = 'Ammonia (NH3)') AS \"NH3 (kt)\",\n",
    "    SUM(releases.annual_load/1000000) FILTER (WHERE substance_name = 'Particulate matter (PM2.5)') AS \"PM2.5 (kt)\",\n",
    "    SUM(releases.annual_load/1000000) FILTER (WHERE substance_name = 'Particulate matter (PM10)') AS \"PM10 (kt)\",\n",
    "    SUM(releases.annual_load/1000000) FILTER (WHERE substance_name = 'Carbon monoxide (CO)') AS \"CO (kt)\",\n",
    "    SUM(releases.annual_load/1000) FILTER (WHERE substance_name = 'Lead and compounds (as Pb)') AS \"Pb (t)\",\n",
    "    SUM(releases.annual_load/1000) FILTER (WHERE substance_name = 'Cadmium and compounds (as Cd)') AS \"Cd (t)\",\n",
    "    SUM(releases.annual_load/1000) FILTER (WHERE substance_name = 'Mercury and compounds (as Hg)') AS \"Hg (t)\",\n",
    "    SUM(releases.annual_load*1000) FILTER (WHERE substance_name = 'PCDD + PCDF (dioxins + furans)(as Teq)') \n",
    "    AS \"PCDD/ PCDF (dioxins/ furans)(g I-Teq)\",\n",
    "    SUM(releases.annual_load/1000) FILTER (WHERE substance_name = 'Polycyclic aromatic hydrocarbons (PAHs)') AS \"PAHs (t)\",\n",
    "    SUM(releases.annual_load) FILTER (WHERE substance_name = 'Hexachlorobenzene (HCB)') AS \"HCB (kg)\",\n",
    "    SUM(releases.annual_load) FILTER (WHERE substance_name = 'Polychlorinated biphenyls') AS \"PCBs (kg)\"\n",
    "\n",
    "FROM facilities\n",
    "    JOIN releases ON facilities.id = releases.facility_ID\n",
    "    JOIN activities ON releases.facility_ID = activities.facility_ID\n",
    "\n",
    "WHERE facilities.year = :year AND releases.compartment = 'Air' AND activities.main_activity = 1\n",
    "GROUP BY facilities.id\n",
    "ORDER BY name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sql_query_result.DataFrame()\n",
    "data.info()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fill GNFR and stack height columns with proper values derived from prtr activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnfr_mapping = {}\n",
    "chimney_mapping={}\n",
    "with open('data/gnfr_mapping.csv', newline='') as mapping_file: \n",
    "    for line in csv.reader(mapping_file, delimiter=';'): \n",
    "        gnfr_mapping[line[0]] = line[2]\n",
    "        chimney_mapping[line[0]] = line[3]\n",
    "\n",
    "data.replace({'GNFR': gnfr_mapping}, inplace=True) # GNFR sector mapping\n",
    "data.replace({'Height class': chimney_mapping}, inplace=True) # Stack height mapping\n",
    "\n",
    "# Make sure all point sources have GNFR and stack height set\n",
    "assert len(data[data['GNFR'] == '']) == 0, f\"There are still {len(data[data['GNFR'] == ''])} point sources with GNFR listed as '<empty>'!\"\n",
    "assert len(data[~data['GNFR'].str.contains('_')]) == 0, f\"There are still {len(data[~data['GNFR'].str.contains('_')])} point sources with GNFR listed as '<prtr key>'!\"\n",
    "assert len(data[~data['Height class'].str.isnumeric()]) == 0, f\"There are still {len(data[~data['Height class'].str.isnumeric()])} point sources with an invalid height class!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure LPS name, GNFR, ID, height class, longitude and latitude are set for all point sources\n",
    "assert len(data[data['LPS'] == '']) == 0, f\"There are {len(data[data['LPS'] == ''])} point source(s) without a name!\"\n",
    "assert len(data[data['GNFR'] == '']) == 0, f\"There are {len(data[data['GNFR'] == ''])} point source(s) without a GNFR sector!\"\n",
    "assert len(data[data['E-PRTR/PRTR Facility ID'] == '']) == 0, f\"There are {len(data[data['E-PRTR/PRTR Facility ID'] == ''])} point source(s) without an ID!\"\n",
    "assert len(data[data['Height class'] == '']) == 0, f\"There are {len(data[data['Height class'] == ''])} point source(s) without a height class!\"\n",
    "assert len(data[data['Longitude (deg)'] == '']) == 0, f\"There are {len(data[data['Longitude (deg)'] == ''])} point source(s) without a longitude value!\"\n",
    "assert len(data[data['Latitude (deg)'] == '']) == 0, f\"There are {len(data[data['Latitude (deg)'] == ''])} point source(s) without a latitude value!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total emissions\n",
    "sum = DataFrame({\"Sum LPS\": data.iloc[:, 8:23].sum()})\n",
    "sum[\"National Total\"] = [1210.50, 1125.02, 291.78, 601.24, 94.66, 207.01, 2957.80, 162.18, 11.94, 8.30, 119.8, 75.71, 12.82, 219.33]\n",
    "sum[\"Percentage\"] = sum[\"Sum LPS\"] / sum[\"National Total\"] * 100\n",
    "sum[\"Problem?\"] = sum[\"Sum LPS\"] >= sum[\"National Total\"]\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check outliers\n",
    "data.boxplot(column = ['NOx (as NO2) (kt)', 'NMVOC (kt)', 'SOx (as SO2) (kt)', 'NH3 (kt)'], figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['NOx (as NO2) (kt)'] > data['NOx (as NO2) (kt)'].quantile(0.98)][['LPS', 'NACE', 'GNFR', 'Height class', 'Longitude (deg)', 'Latitude (deg)', 'NOx (as NO2) (kt)']].sort_values(by=['NOx (as NO2) (kt)'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['NMVOC (kt)'] > data['NMVOC (kt)'].quantile(0.9)][['LPS', 'NACE', 'GNFR', 'Height class', 'Longitude (deg)', 'Latitude (deg)', 'NMVOC (kt)']].sort_values(by=['NMVOC (kt)'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['SOx (as SO2) (kt)'] > data['SOx (as SO2) (kt)'].quantile(0.95)][['LPS', 'NACE', 'GNFR', 'Height class', 'Longitude (deg)', 'Latitude (deg)', 'SOx (as SO2) (kt)']].sort_values(by=['SOx (as SO2) (kt)'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['NH3 (kt)'] > data['NH3 (kt)'].quantile(0.98)][['LPS', 'NACE', 'GNFR', 'Height class', 'Longitude (deg)', 'Latitude (deg)', 'NH3 (kt)']].sort_values(by=['NH3 (kt)'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.boxplot(column = ['PM10 (kt)', 'CO (kt)', 'Pb (t)', 'Cd (t)', 'Hg (t)', 'PAHs (t)'], figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['CO (kt)'] > data['CO (kt)'].quantile(0.9)][['LPS', 'NACE', 'GNFR', 'Height class', 'Longitude (deg)', 'Latitude (deg)', 'CO (kt)']].sort_values(by=['CO (kt)'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Pb (t)'] > data['Pb (t)'].quantile(0.9)][['LPS', 'NACE', 'GNFR', 'Height class', 'Longitude (deg)', 'Latitude (deg)', 'Pb (t)']].sort_values(by=['Pb (t)'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicate coordinates (NECD review finding)\n",
    "data['QA: Duplicate coordinates'] = data[['Longitude (deg)', 'Latitude (deg)']].duplicated(keep=False)\n",
    "data[data['QA: Duplicate coordinates'] == True].sort_values(by=['Longitude (deg)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique key from LPS name, GNFR and stack height (NECD review finding)\n",
    "data['QA: Duplicate key'] = data[['LPS', 'GNFR', 'Height class']].duplicated(keep=False)\n",
    "data[data['QA: Duplicate key'] == True].sort_values(by=['LPS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Write data to CSV file to be copied to Excel CLRTAP template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('output/Convert ePRTR data to CLRTAP LPS.csv', index=False, sep='|', decimal=',', columns=['LPS', 'GNFR', 'E-PRTR/PRTR Facility ID', 'Height class', 'Longitude (deg)', 'Latitude (deg)', 'NOx (as NO2) (kt)', 'NMVOC (kt)', 'SOx (as SO2) (kt)', 'NH3 (kt)', 'PM2.5 (kt)', 'PM10 (kt)', 'CO (kt)', 'Pb (t)', 'Cd (t)', 'Hg (t)', 'PCDD/ PCDF (dioxins/ furans)(g I-Teq)', 'PAHs (t)', 'HCB (kg)', 'PCBs (kg)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Create shapefile and inline map to visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "\n",
    "locations = geopandas.GeoDataFrame(data, geometry=geopandas.points_from_xy(data['Longitude (deg)'], data['Latitude (deg)']), crs='epsg:4326')\n",
    "locations.to_file('output/geo/Convert ePRTR data to CLRTAP LPS.shp', encoding='utf8')\n",
    "\n",
    "germany = geopandas.read_file('data/geo/germany.geo.json').plot(figsize=(15, 15), alpha=0.3, edgecolor='k')\n",
    "locations.plot(\"GNFR\", ax=germany, legend=True, figsize=(15, 15), alpha=0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
